{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b10297e6-e772-4d8d-bb19-9d32b274df3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Track images for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39677ddd-4985-4e09-b5d7-6baf16ef90a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!lamin init --storage \"mnist-100\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6da0e15-c949-466c-b395-edc6bf94f0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lamindb as ln\n",
    "import pandas as pd\n",
    "\n",
    "ln.track()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efdaf9c-a9eb-4c77-bedc-d8718fdfcfcf",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# prepare local data\n",
    "import boto3\n",
    "from pathlib import Path\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "bucket = s3.Bucket(\"bernardo-test-bucket-1\")\n",
    "for obj in bucket.objects.filter(Prefix=\"mnist-100/\"):\n",
    "    if not obj.key.endswith(\"/\"):\n",
    "        Path(obj.key).parent.mkdir(exist_ok=True)\n",
    "        bucket.download_file(obj.key, obj.key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a1dafa-bbe4-4ac7-9e39-c7af9e17d54a",
   "metadata": {},
   "source": [
    "Assume we have a local directory of files that we'd like to ingest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f8b795",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls mnist-100/images*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6dd6d3-82c1-4342-879e-8666230ef6c1",
   "metadata": {},
   "source": [
    "And a `.csv` file containing the labels for each of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd8f27f-1b3c-4b8e-8810-3979ef45a1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(\"mnist-100/labels.csv\")\n",
    "labels_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6ed5d2b-0c9d-4a79-837b-5c8137317293",
   "metadata": {},
   "source": [
    "## Ingest images and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c79f86d-c7e7-4e2d-b54e-8dc399223d4d",
   "metadata": {},
   "source": [
    "Let's ingest each image in the folder as a `File` record by leveraging the `Folder` entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665c1808-7813-4aec-ba19-71eb2f188eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_folder = ln.Folder(\"mnist-100/images\")\n",
    "ln.add(img_folder);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bf5f7e-9567-4396-b494-7704d18e7556",
   "metadata": {},
   "source": [
    "Let's also ingest the labels file as a single data object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bddadc-dd9c-4442-b4ab-f8857a50da12",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ln.File(\"mnist-100/labels.csv\")\n",
    "ln.add(labels);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb80100d",
   "metadata": {},
   "source": [
    "```{important}\n",
    "\n",
    "We can equally well pass cloud locations!\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "409f29bd-2044-4051-9323-94db3cf0fac2",
   "metadata": {},
   "source": [
    "## Create the PyTorch Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63b9634-5ecb-4eb8-a402-209d7af232bf",
   "metadata": {},
   "source": [
    "Let's query the relevant data objects to instantiate a [canonical PyTorch custom image dataset](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d955c8f-3b4f-4c6d-8fa4-2d9b1c29f384",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# define the custom dataset class, as seen in the PyTorch guide\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, annotations_file, img_dir, transform=None, target_transform=None\n",
    "    ):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path).to(torch.float32)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982f1a37-0970-41fb-bbad-224b4cdb1dba",
   "metadata": {},
   "source": [
    "The canonical PyTorch dataset takes as input the path to a folder with images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8154d6ae-7ea7-4782-9102-b660e4ae9f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_folder = ln.select(ln.Folder).one()\n",
    "img_folderpath = img_folder.path()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbbe5e1-84c2-4181-84f5-57af0c29a1e0",
   "metadata": {},
   "source": [
    "As well as the path to a csv file with labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcd5b5a-4a10-4b28-8c73-9abe19a8b79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ln.select(ln.File, suffix=\".csv\").one()\n",
    "labels_filepath = labels.path()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9aa2b3a4",
   "metadata": {},
   "source": [
    "Let's now instantiate the canonical PyTorch custom image dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795e6c70-ca26-448a-a9e7-3033e27e4e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomImageDataset(labels_filepath, img_folderpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aea514-5f87-4443-9c19-f6ab492b5a50",
   "metadata": {},
   "source": [
    "## Create the PyTorch DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e033032c-57ae-4f8d-8364-6b39937b8dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "# define train and test splits\n",
    "train_subset, test_subset = random_split(dataset, [80, 20])\n",
    "\n",
    "# create train an test Dataloaders based on splits\n",
    "train_loader = DataLoader(train_subset.dataset)\n",
    "test_loader = DataLoader(test_subset.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead3af92-59e8-4c97-86f2-9185cefed6d8",
   "metadata": {},
   "source": [
    "## Train a simple autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7dd583-b394-4b46-8207-bcb76733fb99",
   "metadata": {},
   "source": [
    "We can now train a [canonical PyTorch Lightning autoencoder](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3542b283-9ad2-4615-a20c-205dc941dda2",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim, nn\n",
    "from torchmetrics import Accuracy\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# torch.set_default_dtype(torch.uint8)\n",
    "\n",
    "encoder = nn.Sequential(nn.Linear(28 * 28, 64), nn.ReLU(), nn.Linear(64, 3))\n",
    "decoder = nn.Sequential(nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, 28 * 28))\n",
    "\n",
    "\n",
    "class LitAutoEncoder(pl.LightningModule):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.test_accuracy = Accuracy(task=\"multiclass\", num_classes=9)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = nn.functional.mse_loss(x_hat, x)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "autoencoder = LitAutoEncoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65694112-4d70-480e-9f17-e2c438e5e7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(limit_train_batches=100, max_epochs=5)\n",
    "trainer.fit(model=autoencoder, train_dataloaders=train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "nbproject": {
   "id": "GfLCSYv8BjvJ",
   "parent": null,
   "pypackage": null,
   "time_init": "2023-02-21T17:45:22.205882+00:00",
   "user_handle": "testuser1",
   "user_id": "DzTjkKse",
   "user_name": "Test User1",
   "version": "0"
  },
  "vscode": {
   "interpreter": {
    "hash": "6f775e615af92107a24a8dc5e93fe95ce25fd35096484e8bc738bef7b5ea6eb7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
